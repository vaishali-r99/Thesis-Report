% \chapter{Introduction}
% \label{chap:Introduction}
% Fluid mechanics plays a pivotal role in the progress of various diverse fields, including aerospace and automotive engineering, energy system optimization, environmental modeling, biomedical research, and countless other critical domains that shape our technological and scientific landscape. Partial Differential Equations (PDEs), in particular the Navier-Stokes equations, which provide the mathematical framework for analyzing the behaviour of fluid flow for these complex problems are often intractable, i.e; they do not have exact analytical solutions. Thus, they still remain an open problem in the world of mathematics. Hence, the solutions to the Navier-Stokes equations are approximated using numerical methods such as the Finite Element or the more commonly used Finite Volume Method (FVM) which rely on spatial and temporal discretization of PDEs. With the advent of software and technology, emerged the field of Computational Fluid Dynamics (CFD), leveraging computer algorithms for numerical simulations of fluid flow problems. However, these simulations are computationally intensive and may take from several hours to several weeks for complex flows and/or geometries. Although advances in high-performance computing and parallel processing have been a game-changer for CFD, there still remain several complications with respect to grid dependency, convergence issues, model assumptions and simplification of underlying physics, numerical errors as well as turbulence modelling. \\
% The most problematic use-case is turbulence modelling, which is marked by velocity and pressure fluctuations, a wide range of length and time scales - from large vortices down to small eddies and numerical instabilities. In addition, modelling turbulence near walls presents unique problems on its own which requires specialized treatments and techniques in these near-wall regions. Accurately modelling all the intricate phenomena of the turbulent regime, called the Direct Numerical Simulation (DNS), is possible, but at the cost of a huge amount of computational resources, complexity and simulation times. Consequently, in many practical scenarios, simplified turbulence models are employed, even though this comes at the expense of accuracy. \\
% Advancements in the dynamic field of CFD over the past had seen substantial efforts channeled into enhancing turbulence models, improving meshing techniques, efficient Reduced Ordered Modelling (ROM) surrogates and reducing computational complexity. While numerous techniques and models exist to address various turbulence-related challenges, there is no universally applicable model that consistently delivers accurate results across all turbulence settings. As a result, the computational bottleneck often remains an unavoidable obstacle. In response to this challenge, in recent times, there has been a growing interest in implementing Machine Learning (ML) algorithms, specifically to enhance the cost-effectiveness of CFD methods. Although training an ML model is often very computationally demanding, a trained model can quickly make predictions on new data, a significant advantage over the commonly used numerical methods. The integration of ML in CFD represents a paradigm shift, enabling simulations to move beyond traditional physics-based models. The synergy between Deep Learning (DL) and CFD offers the potential to uncover novel insights into fluid dynamics, for example, Convolutional Neural Networks (CNNs) can extract relevant features and classify flow regimes whereas Recurrent Neural Networks (RNNs) can predict fluid behaviors based on temporal data for unsteady flows. Incorporating neural networks into fluid dynamics problems not only improves the accuracy and efficiency of simulations, but also opens up new doors for understanding flow behaviours and strategies for flow control and optimization. As neural networks continue to evolve and adapt to the specific challenges of fluid dynamics, they promise to be a pivotal component in the advancement of CFD across various industries and applications. \\
% So far, ML methods have been employed in fluid dynamics research but have not been in engineering practice. Some possible explanations for this might be the scarcity of huge datasets that are open and can be publicly accessed and the poor generalization performance of ML techniques on previously unseen data. This thesis attempts to tackle the generalization problem by implementing a novel approach that leverages Graph Neural Networks (GNNs) for accurate and efficient predictions for the application of nozzle flow simulation. 
% \section{Literature Review}
% In this section, relevant research and work done with respect to ML in the context of CFD, especially in turbulence modelling is discussed. The evolution of turbulence modeling is a dynamic field with notable milestones and contributions. The pioneering work of Osborne Reynolds in the late 19th century laid the foundation for turbulence research, leading to the eddy viscosity hypothesis and the rise of Reynolds-averaged Navier-Stokes (RANS) modelingdvancements in the dynamic field of CFD over the past had seen substantial efforts channeled into enhancing turbulence models, improving meshing techniques, efficient Reduced Ordered Modelling (ROM) surrogates and reducing computational complexity. While numerous techniques and models exist to address various turbulence-related challenges, there is no universally applicable model that consistently delivers accurate results across all turbulence settings. As a result, the computational bottleneck often remains an unavoidable obstacle. In response to this challenge, in recent times, there has been a growing interest in implementing Machine Learning (ML) algorithms, specifically to enhance the cost-effectiveness of CFD methods. Although training an ML model is often very computationally demanding, a trained model can quickly make predictions on new data, a significant advantage over the commonly used nu in the mid-20th century. The K-epsilon model, introduced in the 1970s, significantly enhanced RANS modeling by striking a balance between accuracy and computational efficiency. Parallel to this development, Large Eddy Simulation (LES) emerged as a complementary approach, aiming to capture large-scale turbulent eddies directly while modeling smaller ones. Advances in computational power enabled the feasibility of LES, particularly for complex geometries and higher Reynolds numbers. Direct Numerical Simulation (DNS), which resolves all turbulent scales, became increasingly attainable due to further advancements in computational resources. Recent research has focused on improving existing models, developing advanced closure schemes, and exploring the use of machine learning techniques. The combination of RANS and LES techniques in hybrid models has also gained traction, offering a promising path towards more efficient and accurate simulations. \\
% More recently, machine learning and deep learning-based turbulence modeling are gaining traction. ML algorithms have been employed to develop surrogate models, which are reduced-order representations of complex turbulence systems. These models are significantly faster to evaluate than full Navier-Stokes simulations, making them suitable for real-time applications and design optimization. Additionally, ML has been used to create data-driven closure terms for RANS and LES models, enhancing the accuracy of turbulence simulations. DL techniques, particularly CNNs and RNNs, have demonstrated remarkable performance in turbulence modeling. These neural networks can effectively learn complex patterns and relationships in turbulent data, enabling the prediction of turbulence quantities from limited input data as well as for non-equilibrium flows and multiphase flows. \\
% It wasn't until the early 2010s that researchers and engineers began exploring the potential of applying machine learning techniques to problems in CFD. One of the earliest works in this field is that of Brunton (cite!!!), who provided a comprehensive review of ML methods applied to fluid mechanics and classifies them into three major categories - supervised, semi-supervised and unsupervised. In supervised learning, the model is trained on labeled data, where the input (features) and the corresponding output (target) are known. Supervised machine learning algorithms can be categorized into classification and regression approaches. Classification algorithms are used to predict categorical outcomes, while regression algorithms are used to predict continuous outcomes. In the context of turbulence modeling, regression algorithms are particularly valuable, as they can be used to predict turbulence quantities such as turbulent viscosity and eddy dissipation rate. Random forests, support vector machines, and neural networks are among the commonly used supervised learning techniques, applicable to both classification and regression tasks. Semi-supervised learning blends aspects of both supervised and unsupervised machine learning. It has been effectively used in tasks involving time-series data and image processing. Unsupervised learning involves training on unlabeled data to discover patterns, groupings, or structures within the data and unlike supervised learning there are no specified prediction targets. Techniques like Reduced Order Modelling (ROM), Proper Orthogonal Decomposition (POD), dimensionality reduction and Clustering fall under unsupervised learning and they mark the precursors of data-driven methods in fluid mechanics. \\
% Another way of classifying ML techniques would be based on their optimization objective. The commonly used Data Driven approaches try to minimize the error between the predictions and target solutions by training available data in a supervised manner without explicitly considering physical laws. Data-driven flow solvers are typically tailored and trained for specific target applications to ensure consistent and high accuracy across cases. While these approaches reduce inference time, the computational burden shifts to a pre-processing phase, involving data generation and model parameter tuning. Physics Informed Neural Networks (PINNs) make use of prior knowledge, for example mathematical models and equations that govern the data and enforce physical intuition for training the model in an unsupervised manner. PINNs can make accurate predictions with limited data, and train models in a faster and computationally efficient way for physics-based problems. \\
% Several intriguing research initiatives in this field will be explored in this section. One of the earliest recognized efforts of using ML methods in turbulence modelling is the work of Zhang and Duraisamy(). In 2015, Duraisamy et al. (cite !!!!) proposed a data-driven method for turbulence closure modelling in which an inverse problem, i.e; Multiscale Gaussian process regression learns adjustable spatio-temporal term(s) of the RANS equations which are then incorporated into the RANS equations and reconstructed into a functional form. This adjusted turbulence model is then used for predictive purposes. The paper by Ling, Kurzawski and Templeton (cite!!!!) introduces deep neural networks to enhance Reynolds-averaged Navier–Stokes turbulence models by embedding Galilean invariance, leading to improved accuracy in predicting Reynolds stress anisotropy and enhanced performance in velocity field predictions compared to traditional models. \\
% Guastoni et al. (2020) proposed a fully-convolutional neural network model to predict streamwise velocity fields in turbulent open channel flow. The model takes streamwise and spanwise wall-shear stress planes as input and is trained using DNS.Taking into account the successful outcomes of this research, Guastoni et al. (2021) compares two models trained using data from DNS to predict the instantaneous velocity fluctuations in a turbulent open-channel flow. The first model, a fully convolutional neural network (FCN), directly predicts the fluctuations, while the second model, known as FCN-POD, reconstructs the flow fields using a linear combination of orthonormal basis functions obtained through POD. CNNs are particularly useful for flow field reconstruction and denoising noisy data generated from numerical simulations. Zhang et al. () to predict the lift coefficients of airfoils by analyzing images of the airfoils and their surrounding flows. These images encode flow conditions, such as Mach number, as pixel intensities, allowing the CNN to learn the intricate relationship between airfoil geometry and flow behavior. Viquerat and Hachem ()developed a CNN optimized for estimating drag coefficients of various 2D geometries in laminar flow, trained on a comprehensive dataset of random shapes and their corresponding drag forces. This approach significantly improved drag coefficient predictions for real-world geometries like NACA airfoils. Yilmaz and German () applied a CNN to directly predict airfoil performance based solely on airfoil shape, eliminating the need for time-consuming surrogate modeling techniques requiring manual parameter fitting. Guo et al. trained a deep CNN to generate rapid, albeit less accurate, visual approximations of steady-state flow around 2D objects, streamlining the design process.\\
% In CFD simulations, researchers often encounter unstructured mesh data, particularly when dealing with curved or complex geometries. Traditional CNNs, however, are designed for structured grid data, such as images, where the arrangement of data points is regular and grid-like. This limitation prevents CNNs from being directly applied to unstructured mesh flow field data. To address this issue, researchers have explored the utilization of mesh-free techniques and graph-based representations of fluid data. Recent advancements in manipulating unstructured data have led to the development of mesh-free inference methods for point cloud representations and reduced-order models based on graph-based representations of fluid data. Graph theory-based methods have been successfully employed to identify coherent structures within turbulent flow. Hadjighasem et al. proposed a heuristic based on the generalized eigenvalue problem of the graph Laplacian to determine the locations of coherent structures. This work was extended by Meena et al., who constructed a graph to represent the mutual interaction of individual vortex elements and identified larger vortex communities using network theory-based community detection algorithms. Trask et al. introduced the concept of GMLS-Nets, which parameterize the generalized moving least-squares functional regression technique for application on mesh-free, unstructured data. They demonstrated the effectiveness of GMLS-Nets for uncovering operators governing the dynamics of partial differential equations and predicting body forces associated with flow around a cylinder based on point measurements. \\ %recheck paragraph
% Ogoke et al. () implemented a novel approach for using graph convolutional networks (GCNNs) to predict the drag force associated with laminar flow around airfoils from scattered velocity measurements. GNNs can also be integrated with meta-learning techniques to adapt and improve turbulence models based on specific simulation conditions. This enhances model performance and robustness, particularly in cases with limited training data. The work of Liu et al 2023 uses a meta-learning approach for improving the out-of-distribution (OoD) generalization performance of data-driven models in airflow simulations using graph neural networks (GNNs). In the light of promising results obtained from GNN-based architectures for data-driven turbulence modelling, a GNN-based surrogate model is proposed to understand the various parameters affecting the outcome of the turbulent flow in the context of a High-speed Orienting Momentum with Enhanced Reversibility (HOMER) nozzle, developed by Michele Trancossi.(cite!!)
% \section{Scope and Objectives}

% Why Graph Neural Networks?

% 1. Poor generalization by other ML methods
% 2. CNN required problems to be converted to images and the output was also images. GNN uses the underlying structure of CFD meshes 
% 3. Irregular meshing is also possible whereas CNN could only operate on regular grid.

% The intersection of machine learning and CFD remains an active area of research, with ongoing work in improving the accuracy and efficiency of CFD simulations, and advancements in physics-informed models for its application to a wider range of real-world problems.
