\chapter{Introduction}
\label{chap:Intro}
Fluid mechanics, a foundational branch of physics and engineering, underpins technological advancements in numerous critical sectors, including aerospace, automotive engineering, energy systems, environmental science, and biomedical engineering. The predictive modelling of fluid flow is central to the design, optimization, and operational efficiency of countless applications that fuel technological and scientific progress. At the heart of fluid mechanics are the \gls{NSE}, a set of \gls{PDE} that describe the motion of fluids in space and time. Despite their foundational importance, these equations pose significant challenges due to their complexity, often defying exact analytical solutions and remaining one of the most perplexing open problems in mathematics \cite{fefferman2006existence}. These difficulties ushered in the era of \gls{CFD}, a transformative approach employing numerical methods to approximate solutions to the NSE. CFD has become an indispensable tool, leveraging advanced computing algorithms to simulate fluid flow scenarios. CFD still grapples with computational intensity and a suite of issues ranging from grid dependency to convergence challenges  \cite{ferziger2002computational}, underscoring a persistent need for innovation.\\
Turbulence modelling, in particular, stands out as a formidable challenge. Turbulence is characterized by velocity and pressure fluctuations across a diverse range of scales, from large vortices to minute eddies, compounded by numerical instabilities, especially in regions close to walls. While \gls{DNS} offers an avenue for precise modelling, its demand for extensive computational resources often renders it impractical for routine applications  \cite{moin1998direct}. Consequently, in many practical scenarios, simplified turbulence models are employed, even though this comes at the expense of accuracy.\\
Advancements in the dynamically evolving field of CFD have seen substantial efforts channeled into enhancing turbulence models \cite{pope2000turbulent}, improving meshing techniques \cite{thompson1998automatic}, developing efficient \gls{ROM} surrogates \cite{benner2015survey}, and reducing computational complexity \cite{schmid2010dynamic}. The pursuit of efficiency and optimization in CFD, marked by a growing interest in \gls{ML} and \gls{DL}, has led to the application of these technologies for fluid dynamics. Unlike traditional computational methods, which are tethered to the constraints of processing power and simulation time, DL algorithms, once trained, can offer rapid predictions for new data sets. The integration of DL into CFD represents a promising frontier, offering rapid predictions for new data sets and the potential to generate novel insights into fluid dynamics (\cite{kutz2017deep}, \cite{raissi2019physics}).\\
% The potential for DL to enhance CFD extends beyond mere computational savings; it encompasses the ability to generate novel insights into fluid dynamics, streamline flow control and optimization strategies, and ultimately transform the way we approach fluid mechanics research and applications. \\ 
Despite the advancements, DL methods have not yet been widely adopted in engineering practice, possibly due to the scarcity of extensive datasets and the poor generalization performance on previously unseen data \cite{brenner2019perspective}. This thesis attempts to tackle the generalization problem by leveraging \gls{GNN} to enable precise and efficient predictive models, specifically tailored for the nuanced application of nozzle flow simulation.
% Thus far, DL methods have been employed in fluid dynamics research but have not yet been widely adopted in engineering practice. Some possible explanations for this might be the scarcity of extensive datasets that are openly accessible and the poor generalization performance of ML techniques on previously unseen data. 
\section{Literature review}
In this section, we review significant contributions and advancements in the intersection of ML and CFD, with a particular focus on turbulence modelling. The foundational work in turbulence modeling can be traced back to Osborne Reynolds, who, in the late 19th century, pioneered the concept of turbulence through studies on fluid flow in pipes \cite{reynolds1895dynamical}. However, it was only in the 20th century that significant strides were made in formalizing turbulence models. The 1970s saw the introduction of the k-$\epsilon$ model \cite{launder1974application}, which improved RANS models by balancing accuracy with computational demands. Increased computational capabilities later enabled the adoption of DNS and \gls{LES} \cite{smagorinsky1963general} for more precise flow simulations. Recent trends show hybrid RANS-LES models emerging as a promising approach for accurate simulations.\\
ML algorithms have been increasingly deployed to construct surrogate models for complex turbulence systems. These surrogate models, embodying reduced-order representations, offer a streamlined computational alternative to exhaustive simulations. By the early 2010s, the exploration of ML in CFD began with significant contributions like Brunton's review \cite{brunton}, categorizing ML techniques into supervised, semi-supervised, and unsupervised learning. Supervised learning involves training models on well-labeled datasets to predict predefined outcomes, with regression algorithms playing a pivotal role in predicting continuous variables, such as turbulence quantities. Semi-supervised learning, blending elements of supervised and unsupervised learning, has shown effectiveness in analyzing time-series data and images. Unsupervised learning focuses on unlabeled data and identifies patterns, clusters, or structures using methodologies like ROM and POD \cite{berkooz1993proper}.\\
Beyond traditional classification, ML techniques can be discerned by their optimization goals into physics-informed and data-driven methods. Physics-informed methods integrate domain-specific knowledge, typically based on physical laws and principles, into the model formulation. They rely less on large amounts of data, as they primarily leverage the governing equations of the system. Termed \gls{PINN} \cite{raissi2019physics}, these methods are suitable when the physics of the problem is well-understood and when data may be sparse or expensive to obtain. \\
In contrast, data-driven models aim to reduce the prediction error, relying on available data to make predictions or decisions. DL has facilitated the generation of data-driven closure terms for RANS and LES models, significantly elevating the precision of turbulence simulations \cite{ling2016}. Among the spectrum of DL methodologies, \gls{CNN} and \gls{RNN} have emerged as particularly potent in modelling turbulence. They adeptly capture and learn from the complex patterns inherent in turbulent flows. This capability extends to challenging scenarios such as non-equilibrium and multiphase flows. Milano and Koumoutsakos \cite{milano2002} explored the use of neural networks for approximating flow fields around complex geometries, setting a precedent for DL in fluid mechanics. Tracey, Duraisamy, and Alonso (\cite{tracey2013}) introduced machine learning techniques to modify turbulence models, illustrating ML's potential to refine simulation models. Zhang and Duraisamyâ€™s work \cite{zhang2015} on data-driven turbulence closure models via multiscale Gaussian process regression paved the way for enhanced RANS equations. \\
Subsequent research efforts have further broadened the application of ML in CFD.  More recently, Parish and Duraisamy \cite{parish2016} leveraged ML to inform turbulence model discrepancies, enhancing predictive capabilities. Ling, Kurzawski, and Templeton \cite{ling2016} significantly advanced RANS models' accuracy by incorporating Galilean invariance through deep neural networks. This period also witnessed the utilization of fully-convolutional neural networks by Guastoni et al. \cite{guastoni2020} for predicting velocity fields in turbulent flows, demonstrating the applicability of DL in fluid dynamics.\\
Expanding the scope to unstructured mesh data, recent advancements have explored graph-based and mesh-free techniques for fluid data representation. Trask et al. \cite{trask2019} introduced GMLS-Nets for mesh-free data analysis, demonstrating the versatility of ML approaches in handling complex data structures. Furthermore, Ogoke et al. \cite{ogoke2020} demonstrated the effectiveness of \gls{GCNN} in predicting drag forces around airfoils. Liu et al. \cite{metalearning} showcased the effectiveness of GCNNs and meta-learning in predicting flow dynamics and enhancing turbulence models, highlighting the adaptive capabilities of GNNs in fluid dynamics.\\
In light of these developments, this research proposes a GNN-based surrogate model to analyze unstructured mesh data arising from turbulent flow within a \gls{HOMER} nozzle, developed by Michele Trancossi \cite{trandum}.
\section{Scope and objectives}
This thesis focuses on the cutting-edge intersection of DL, specifically GNNs, and CFD to enhance the predictive modelling of turbulent nozzle flow simulations. Traditionally, reaching the stable solutions entails running simulations for extensive time intervals, a process that requires considerable computational resources and time. This thesis introduces surrogate models that circumvent the need for prolonged simulation times. By capturing transitional solutions at earlier stages which take significantly less time, and processing them through a surrogate model, we can predict stable, steady-state solutions more efficiently. This approach utilizes GNNs as the core technology for the surrogate models, aiming to significantly reduce the computational burden associated with traditional CFD simulations. The research encapsulated within this thesis covers the development, evaluation, and practical application of a GNN-based surrogate model tailored for nozzle flow simulations. Furthermore, we employ data analysis techniques to categorize simulations based on velocity ratios and Coanda effect occurrences. The objectives set forth outline a clear and structured path towards achieving the goals of this research and its outcomes.
\begin{enumerate}
\item \textbf{Develop a GNN model for predicting nozzle flow simulation quantities:} 
% model capable of accurately predicting stable, steady-state solutions of nozzle flow problems.
The primary objective is to design and train a GNN model, that serves as a surrogate, to accurately predict the steady-state velocity and pressure fields of nozzle flow simulations from early, transition states. This model leverages short-term, less computationally intensive simulation results to accurately forecast stable, steady-state flow conditions.
% This surrogate model aims to leverage short-term, less computationally intensive simulation results to accurately forecast stable, steady-state flow conditions .
% This entails utilizing early, transient state simulations to predict stable, steady-state flow conditions accurately.
% The primary objective is to design and train a GNN model capable of accurately predicting the stable, steady-state outcomes of nozzle flow simulations. Quantities, such as velocity and pressure, within a simulation environment. This involves training the model on high-fidelity CFD-generated datasets to learn the complex relationships governing nozzle flow dynamics.
\item \textbf{Investigate the accuracy, efficiency and feasibility of the surrogate model:} This research seeks to assess the viability of the developed GNN model as a surrogate to traditional CFD simulations for nozzle flow analysis. The surrogate model's efficiency, in terms of computational resources and time, will be evaluated against conventional simulation methods to establish its practicality for real-world applications.
% To evaluate the GNN surrogate model in terms of computational efficiency, its feasibility as a sustainable alternative to time-consuming \gls{CFD}simulations , and its precision in mirroring CFD-derived steady-state conditions.
This includes an examination of the model's accuracy as well as a detailed comparison between the steady-state solutions predicted by the GNN models and those obtained from traditional CFD simulations, highlighting the computational savings, and potential limitations.
\item \textbf{Perform clustering on low-dimensional data to classify simulations:} Another aspect of this thesis is the application of clustering techniques to low-dimensional representations of simulation data. The goal is to categorize simulations based on the velocity ratios between the two inlets of the nozzle to determine occurrences of complete adhesion of the outflow jet to the Coanda surface (referred to in this work as Coanda adhesion) and identify to which wall the complete adhesion takes place. This objective aims to provide deeper insights into the simulation outcomes, facilitating more effective analysis and optimization of nozzle designs and flow conditions.
\item \textbf{Investigation of advanced GNN architectures for enhanced model performance}: To explore the potential benefits of incorporating advanced GNN architectures and training strategies, aiming to optimize the model's performance for the complex task of predicting fluid dynamics in nozzle flow scenarios.
\end{enumerate}
% By achieving these objectives, the thesis intends to contribute significantly to the field of CFD by integrating DL techniques to improve simulation accuracy and efficiency. Moreover, it aims to offer novel methodologies for analyzing and interpreting complex fluid dynamics simulations, ultimately 
Together, these objectives aim to substantially contribute to the field of turbulence modelling using DL techniques, guiding future research and application developments in nozzle flow dynamics and beyond. They offer efficient, and adaptable surrogate modeling approach for simulating the dynamics of nozzle flows, thereby reducing the dependence on extensive computational resources and time.